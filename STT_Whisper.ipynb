{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vHPv9ACvTVk",
        "outputId": "234528d3-6666-4a7d-addb-4eb6c07446d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.6.0+cu124)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchaudio) (3.0.2)\n",
            "üîπ Using OpenAI Whisper API for transcription...\n",
            "‚ö†Ô∏è OpenAI API failed. Using Hugging Face Whisper instead...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìú Full Transcription:\n",
            "\n",
            " Hello, and welcome to Effortless English again. As always, if you would like text all the writing for this podcast, and if you would like a vocabulary lesson and the mini story lesson, you can join Effortless English. Go to www.effortlessenglish.com.  You can try one month for only $1.99. And after that, sign up. Okay, let's get started. Today's podcast is titled, No Pain, No Gain. My knees are killing me. I'm only running nine miles. I don't think I'll ever be able to do a marathon. What should I do? Mike asked. How long have you been training? I asked. One month. one month.  and you're trying to run nine miles already. You should cut back. Only increase your mileage by one mile per week. Build up gradually,\" I said. What about your speed? How do you feel when you run? Are you breathing hard?\" I asked. Yeah, I try to push myself and go as fast as possible, Mike said. Yikes! Don't do that. You're training for a marathon, not a sprint. You should run slowly most of the time. You shouldn't be breathing heavily.  heavily when you run. In fact, you should be able to chat while you're running. My advice is to run slower and run shorter. You will then automatically and effortlessly build up to running a marathon,\" I said. Unfortunately, Mike didn't take my advice. He believed in a no pain, no gain philosophy. Running slowly and easily didn't feel like work to him, so he thought it couldn't help. Instead, he kept trying.  trying to run faster and farther as soon as possible. His knee problems became worse. Finally, he was forced to quit. He never did run a marathon. I, on the other hand, used my slow, steady, easy approach to complete two marathons. I never had knee problems or foot problems or any injuries whatsoever. I never felt the training was painful or arduous. I enjoyed my training runs. Most of them felt easy and effortless.  I often think of Mike when I talk to my English students. Invariably, there are students who question my effortless approach. They too have a no-pain, no-gain belief. They think they cannot learn English unless they strive and suffer. So they spend long hours memorizing grammar textbooks. They spend long hours doing TOEFL practice tests and textbook exercises. I tell them to relax. I tell them to stop these activities.  and focus on interesting, comprehensible listening and reading. But many don't listen. They continue with the painful approach. They become increasingly frustrated. Some even become angry, especially when they see the effortless approach students improving much faster. They feel it's unfair that their pain is not rewarded. They resent that their painful efforts are so slow and ineffective. eventually do get it.  and switch to an effortless approach, but some never do. They just keep doing the same thing. They grow more bitter and frustrated, just like Mike when he tried to train for a marathon. Many finally quit. Don't be like Mike. No pain, no gain is a lie. If you enjoy the process of learning English, you will, in fact, gain more and gain faster. If you use an effortless approach, your grammar, listening, speech...  Speaking, reading, and writing will all improve faster than if you use a painful textbook approach. Put away the grammar books. Put away the textbooks. Find interesting and understandable English material. Listen, listen, listen to it every day. Read, read, read for fun every day. Join an effortless system, such as Effortless English or The Linguist. If you do, I guarantee you will enjoy English more, and you will learn...  faster and more easily than those who insist on following the traditional methods. No pain, big gains. Okay, that's all for this article, No Pain, No Gain. Members, as always, listen to the vocabulary audio lesson and listen to the mini-story. This will help you learn the vocabulary more deeply, more thoroughly. And remember, when you listen to the mini story, try to...  retell the story after you listen to it. That also will help you remember the vocabulary and most importantly, be able to use it. Okay, if you want to join Effortless English, as always go to www.effortlessenglish.com. Bye-bye.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install openai pydub transformers torchaudio\n",
        "\n",
        "import openai\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "# Define the audio file path 
        "audio_file_path = \"No_Pain_No_Gain.mp3\"  
        "\n",
        "# Function to transcribe using OpenAI Whisper API\n",
        "def transcribe_with_openai_whisper(audio_path):\n",
        "    \"\"\"Transcribes long audio using OpenAI's Whisper API\"\"\"\n",
        "    # Update to use the new API call\n",
        "    audio_file= open(audio_path, \"rb\")\n",
        "    transcription = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "    return transcription.text\n",
        "\n",
        "# Function to split and transcribe long audio manually (Backup)\n",
        "def transcribe_with_huggingface_whisper(audio_path):\n",
        "    \"\"\"Splits and transcribes long audio using Hugging Face Whisper\"\"\"\n",
        "    transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-large-v2\")\n",
        "\n",
        "    # Load and split audio into 30-second chunks to avoid the ValueError\n",
        "    audio = AudioSegment.from_mp3(audio_path)\n",
        "    chunk_length_ms = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i+chunk_length_ms] for i in range(0, len(audio), chunk_length_ms)]\n",
        "\n",
        "    transcriptions = []\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk.export(f\"chunk_{i}.mp3\", format=\"mp3\")  # Save chunk\n",
        "        # Pass return_timestamps=True to handle longer audio with Hugging Face Whisper\n",
        "        result = transcriber(f\"chunk_{i}.mp3\", return_timestamps=True)  # Transcribe chunk\n",
        "        # Extract text from the result\n",
        "        transcriptions.append(\"\".join([chunk[\"text\"] for chunk in result[\"chunks\"]]))\n",
        "\n",
        "    return \" \".join(transcriptions)  # Combine chunks\n",
        "\n",
        "# Try OpenAI API first, fallback to Hugging Face if API key is missing\n",
        "try:\n",
        "    print(\"üîπ Using OpenAI Whisper API for transcription...\")\n",
        "    full_transcription = transcribe_with_openai_whisper(audio_file_path)\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è OpenAI API failed. Using Hugging Face Whisper instead...\")\n",
        "    full_transcription = transcribe_with_huggingface_whisper(audio_file_path)\n",
        "\n",
        "# Print full transcription\n",
        "print(\"\\nüìú Full Transcription:\\n\")\n",
        "print(full_transcription)"
      ]
    }
  ]
}
